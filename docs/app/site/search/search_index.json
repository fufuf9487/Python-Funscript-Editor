{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Python Funscript Editor A Python program that use Computer Vision to predict the funscript actions. Most of you are probably interested in the Open Funscripter (OFS) integration of this tool. I create a hacky lua script to integrate the prediction of this tool in OFS. More information in OFS Integration . For the configuration see this Documentation page. NOTE: The Tool could also use as an standalone application with an build in UI. Due to the limitations it is not intended for productive use. User-Guide Algorithms Build Config OFS Integration UI","title":"Home"},{"location":"#python-funscript-editor","text":"A Python program that use Computer Vision to predict the funscript actions. Most of you are probably interested in the Open Funscripter (OFS) integration of this tool. I create a hacky lua script to integrate the prediction of this tool in OFS. More information in OFS Integration . For the configuration see this Documentation page. NOTE: The Tool could also use as an standalone application with an build in UI. Due to the limitations it is not intended for productive use.","title":"Python Funscript Editor"},{"location":"#user-guide","text":"Algorithms Build Config OFS Integration UI","title":"User-Guide"},{"location":"user-guide/algorithms/","text":"Algorithms Create Funscript Action using OpenCV Tracker Idea: By using OpenCV Tracker , we can determine the relative movements in a static camera setup and map them into Funscript actions using simple signal processing. The Algorithm is implemented for 3D Side-By-Side VR Videos. Some parameter are currently hard coded. It should be possible to expand the functionality to 2D Videos by changing the code, with the following limitations. Limitations Static camera setup Fixed reference point of relative movement in video required No video cuts within a tracking sequence allowed No change of position of the performers Features in the video which are visible in all following frames of the tracking sequence required. Process Selection of the features for the Woman and Men in the video, which should be tracked. Predict the feature positions in the following video frames by OpenCV Tracker. Calculate the difference between the predicted tracking boxes. Map the relative difference to an absolute difference score by user input. Filter all local min and max points to get the final action positions for the Funscript. Improvements You can change the OpenCV tracker in the source code which predicts the position. OpenCV offers several trackers which differ in prediction accuracy and processing speed. See also OpenCV Tracker . You can set the number of frames that are interpolated by the skip_frames parameter. 0 means that the OpenCV tracker delivers a prediction for each frame. This is slower but more accurate. Or if greater than zero, the individual frames are skipped and then the tracking boxes are interpolated, which increases the processing speed but decreases the accuracy. I have set the value to 1, i.e. every 2nd frame is skipped and interpolated. Which provides a good mix of accuracy and speed. It is recommended to use a low resolution video e.g. 4K for generating the funscript actions, as the processing speed is higher.","title":"Algorithms"},{"location":"user-guide/algorithms/#algorithms","text":"","title":"Algorithms"},{"location":"user-guide/algorithms/#create-funscript-action-using-opencv-tracker","text":"Idea: By using OpenCV Tracker , we can determine the relative movements in a static camera setup and map them into Funscript actions using simple signal processing. The Algorithm is implemented for 3D Side-By-Side VR Videos. Some parameter are currently hard coded. It should be possible to expand the functionality to 2D Videos by changing the code, with the following limitations.","title":"Create Funscript Action using OpenCV Tracker"},{"location":"user-guide/algorithms/#limitations","text":"Static camera setup Fixed reference point of relative movement in video required No video cuts within a tracking sequence allowed No change of position of the performers Features in the video which are visible in all following frames of the tracking sequence required.","title":"Limitations"},{"location":"user-guide/algorithms/#process","text":"Selection of the features for the Woman and Men in the video, which should be tracked. Predict the feature positions in the following video frames by OpenCV Tracker. Calculate the difference between the predicted tracking boxes. Map the relative difference to an absolute difference score by user input. Filter all local min and max points to get the final action positions for the Funscript.","title":"Process"},{"location":"user-guide/algorithms/#improvements","text":"You can change the OpenCV tracker in the source code which predicts the position. OpenCV offers several trackers which differ in prediction accuracy and processing speed. See also OpenCV Tracker . You can set the number of frames that are interpolated by the skip_frames parameter. 0 means that the OpenCV tracker delivers a prediction for each frame. This is slower but more accurate. Or if greater than zero, the individual frames are skipped and then the tracking boxes are interpolated, which increases the processing speed but decreases the accuracy. I have set the value to 1, i.e. every 2nd frame is skipped and interpolated. Which provides a good mix of accuracy and speed. It is recommended to use a low resolution video e.g. 4K for generating the funscript actions, as the processing speed is higher.","title":"Improvements"},{"location":"user-guide/build/","text":"Build from Source For Windows user i recommend to use the release version from github release page Windows Use pyinstaller in anaconda environment with all packages from requirements.txt set up. Then run: pip install pyinstaller build.bat This create the Windows Package in ./dist Pip-Package (Recommend for Linux) Generate distribution package of this project. These are archives that can be uploaded to an local Package Index and can be installed by pip. make docs package This create the distribution package in ./dist . Or simply type make all to build and install the package.","title":"Build"},{"location":"user-guide/build/#build-from-source","text":"For Windows user i recommend to use the release version from github release page","title":"Build from Source"},{"location":"user-guide/build/#windows","text":"Use pyinstaller in anaconda environment with all packages from requirements.txt set up. Then run: pip install pyinstaller build.bat This create the Windows Package in ./dist","title":"Windows"},{"location":"user-guide/build/#pip-package-recommend-for-linux","text":"Generate distribution package of this project. These are archives that can be uploaded to an local Package Index and can be installed by pip. make docs package This create the distribution package in ./dist . Or simply type make all to build and install the package.","title":"Pip-Package (Recommend for Linux)"},{"location":"user-guide/config/","text":"Python Funscript Editor Config The configuration files for the Windows release version are located in the funscript-editor/funscript_editor/config directory since release v0.0.3 . If you use the python source code directly they are located in funscript_editor/config . Config Files The directory contains several config files. The most interesting are video_scaling.json , settings.yaml and hyperparameter.yaml . When editing the *.yaml configuration files, pay attention to the formatting, otherwise the program will not work later. Config Files: hyperparameter.yaml : hyperparameter for the prediction algorithms logging_linux.yaml : the logging configuration for linx logging_windows.yaml : the logging configuration for windows settings.yaml : application settings ui.yaml : user interface settings video_scaling.json : scaling for the preview window Config Parameter hyperparameter.yaml skip_frames (int): This parameter specifies how many frames are skipped and interpolated during tracking. Increase this parameter to improve the processing speed on slow hardware. But higher values result in poorer predictions! avg_sec_for_local_min_max_extraction (float): Specify the window size for the calculation of the reference value for the local min and max search. min_frames (int): Specify the minimum required frames for the tracking. Wee need this parameter to ensure there is at leas two strokes in the tracking result. shift_top_points (int): Shift predicted top points by given frame number. Positive values delay the position and negative values result in an earlier position. shift_bottom_points (int): Shift predicted bottom points by given frame number. Positive values delay the position and negative values result in an earlier position. top_threshold (float): Define the top threshold. All top points greater than (max - threshold) will be set to the specified max value. Set 0.0 to disable this function. bottom_threshold (float): Define the bottom threshold. All bottom points lower than (min + threshold) will be set to the specified min value. Set 0.0 to disable this function. settings.yaml use_zoom (bool): Enable or disable an additional step to zoom in the Video before selecting a tracking feature for the Woman or Men. zoom_factor: (float): Set the desired zoom value which will be used when the zoom function is activated. use_equirectangular (bool): Convert video in normal perspective view before apply tracking. This should improve the tracking at the border of videos, because there is the distortion very high. equirectangular_scaling (float): scaling parameter for the equirectangular preview window. 1.0 is 1240x720 , 1.5 would be 1860x1080 , ... (Do not use to high scaling values, the perspective calculation need a lot of computer resources!) tracking_direction (str): Specify the tracking direction. Allowed values are 'x' and 'y' . scaling_method (str): Specify the scaling method for the video before apply tracking and the preview window size. Allowed values are 'auto' and 'config' . 'auto' : try to calculate the scaling depending on your screen resolution. If you have a very high screen resolution e.g. 8K Monitor this option will strongly slow down the tracking speed, because all videos are scaled up/down to 8K before tracking. If you set 'config' the scaling form video_scaling.json will be used. You can adjust this config to your like as described in the documentation on github. max_playback_fps (int): Limit the max player speed in the tracking preview window (0 = disable limit) video_scaling.json The video_scaling.json config file specifies how the video get scaled bevor the tracking. The scaling also apply tho the preview size. If the preview to select the tracking feature is to small or to large you have to adjust this config file. The entries in this config file consist of a pair of values. Example config: { \"0\": 2.0, \"1000\": 1.0, \"3500\": 0.5, \"5000\": 0.25 } One pair in the example config is e.g. \"0\": 2.0 . Each pair of values defines which scaling should be used for which video resolution. The first value, refers to the video width in pixels. Videos with size larger than 0 pixels horizontally use a scaling of 2.0 . Videos with 1000 pixel and more are scaled with 1.0 , from 3500 with 0.5 and from 5000 with 0.25 . You can enter as many values as you want and change the existing scaling. It\u2019s best to look at your screen resolution and calculate which scaling you need for which video size so that the window fits on the monitor. e.g. You have 1920x1080 screen and 5400x2700 Video, you can divide 1920 / 5400 = 0.36 \u2192 add \"5300\": 0.35 to the config (the key value have to be a little bit smaller than the Video resolution to apply the correct scaling).","title":"Config"},{"location":"user-guide/config/#python-funscript-editor-config","text":"The configuration files for the Windows release version are located in the funscript-editor/funscript_editor/config directory since release v0.0.3 . If you use the python source code directly they are located in funscript_editor/config .","title":"Python Funscript Editor Config"},{"location":"user-guide/config/#config-files","text":"The directory contains several config files. The most interesting are video_scaling.json , settings.yaml and hyperparameter.yaml . When editing the *.yaml configuration files, pay attention to the formatting, otherwise the program will not work later. Config Files: hyperparameter.yaml : hyperparameter for the prediction algorithms logging_linux.yaml : the logging configuration for linx logging_windows.yaml : the logging configuration for windows settings.yaml : application settings ui.yaml : user interface settings video_scaling.json : scaling for the preview window","title":"Config Files"},{"location":"user-guide/config/#config-parameter","text":"","title":"Config Parameter"},{"location":"user-guide/config/#hyperparameteryaml","text":"skip_frames (int): This parameter specifies how many frames are skipped and interpolated during tracking. Increase this parameter to improve the processing speed on slow hardware. But higher values result in poorer predictions! avg_sec_for_local_min_max_extraction (float): Specify the window size for the calculation of the reference value for the local min and max search. min_frames (int): Specify the minimum required frames for the tracking. Wee need this parameter to ensure there is at leas two strokes in the tracking result. shift_top_points (int): Shift predicted top points by given frame number. Positive values delay the position and negative values result in an earlier position. shift_bottom_points (int): Shift predicted bottom points by given frame number. Positive values delay the position and negative values result in an earlier position. top_threshold (float): Define the top threshold. All top points greater than (max - threshold) will be set to the specified max value. Set 0.0 to disable this function. bottom_threshold (float): Define the bottom threshold. All bottom points lower than (min + threshold) will be set to the specified min value. Set 0.0 to disable this function.","title":"hyperparameter.yaml"},{"location":"user-guide/config/#settingsyaml","text":"use_zoom (bool): Enable or disable an additional step to zoom in the Video before selecting a tracking feature for the Woman or Men. zoom_factor: (float): Set the desired zoom value which will be used when the zoom function is activated. use_equirectangular (bool): Convert video in normal perspective view before apply tracking. This should improve the tracking at the border of videos, because there is the distortion very high. equirectangular_scaling (float): scaling parameter for the equirectangular preview window. 1.0 is 1240x720 , 1.5 would be 1860x1080 , ... (Do not use to high scaling values, the perspective calculation need a lot of computer resources!) tracking_direction (str): Specify the tracking direction. Allowed values are 'x' and 'y' . scaling_method (str): Specify the scaling method for the video before apply tracking and the preview window size. Allowed values are 'auto' and 'config' . 'auto' : try to calculate the scaling depending on your screen resolution. If you have a very high screen resolution e.g. 8K Monitor this option will strongly slow down the tracking speed, because all videos are scaled up/down to 8K before tracking. If you set 'config' the scaling form video_scaling.json will be used. You can adjust this config to your like as described in the documentation on github. max_playback_fps (int): Limit the max player speed in the tracking preview window (0 = disable limit)","title":"settings.yaml"},{"location":"user-guide/config/#video_scalingjson","text":"The video_scaling.json config file specifies how the video get scaled bevor the tracking. The scaling also apply tho the preview size. If the preview to select the tracking feature is to small or to large you have to adjust this config file. The entries in this config file consist of a pair of values. Example config: { \"0\": 2.0, \"1000\": 1.0, \"3500\": 0.5, \"5000\": 0.25 } One pair in the example config is e.g. \"0\": 2.0 . Each pair of values defines which scaling should be used for which video resolution. The first value, refers to the video width in pixels. Videos with size larger than 0 pixels horizontally use a scaling of 2.0 . Videos with 1000 pixel and more are scaled with 1.0 , from 3500 with 0.5 and from 5000 with 0.25 . You can enter as many values as you want and change the existing scaling. It\u2019s best to look at your screen resolution and calculate which scaling you need for which video size so that the window fits on the monitor. e.g. You have 1920x1080 screen and 5400x2700 Video, you can divide 1920 / 5400 = 0.36 \u2192 add \"5300\": 0.35 to the config (the key value have to be a little bit smaller than the Video resolution to apply the correct scaling).","title":"video_scaling.json"},{"location":"user-guide/ofs-integration/","text":"Open Funscripter Integration Currently we use a hacky lua script to communicate between the Python Funscript Generator and the Open Funscripter. Installation (Windows) Download the latest packed Python Funscript Editor from github release page . Extract the Archiv. Download the latest funscript_generator.lua script from github release page . Move the downloaded funscript_generator.lua script to data/lua in your OFS directory. Open the funscript_generator.lua file and adjust the Settings.FunscriptGenerator and Settings.TmpFile variable. NOTE: You have to use use / or \\\\ for the \\ symbols in your path! Settings.FunscriptGenerator : Point to the extracted Python Funscript Editor program (better double check the complete path string to avoid errors later on). Settings.TmpFile : Specifies a temporary file location where to store the result (must be a file not a directory!). The file does not have to exist at the moment. The specified file will be generated from the Python Funscript Editor and will be overwritten automatically at the next time the generator is started! Now launch OFS. Navigate to View : Special functions : Custom Functions and select the funscript_generator.lua entry. Click the Button Bind Script (This may trigger the funscript generator, just ignore it for now). Navigate to Options : Keys : Dynamic and insert a shortcut for the funscript generator. Now you can use the shortcut at any position in the video to start the funscript generator. Troubleshot If you have problems with the OFS integration setup first test if the app work in standalone mode by starting the funscript-editor.exe . This allows the source of the error to be narrowed down more quickly! If the standalone application works, look for your problem in the issues listed below. If the standalone application not work or your issue was not solved by a point listed below, open an issue with a detailed problem description and the full terminal window output if available. After setting the min and max value after tracking no points are inserted in OFS If the points are missing in OFS then most likely the variable Settings.TmpFile in the funscript_generator.lua script is set incorrectly or the generator crashes. A crash could happen if your PC does not have enough memory. The amount of memory required depends heavily on the video resolution! Noting happens when i press the Shortcut for the Funscript Generator In most cases, the variable Settings.FunscriptGenerator in the funscript_generator.lua script was not set correctly. If you are using an older version of the funscript_generator.lua you should download the latest version of the script from the github release page . With older funscript_generator.lua scripts there were e.g. problems with blanks in the path. Important: You have to use use / or \\\\ for the \\ symbols in your path! When calling the generator, only a message box is displayed with the message: \"Video file was not specified!\" In some cases OFS does not set the path to the video file within the lua script correctly (the variable VideoFilePath is empty). Mostly it helps to save the current project and/or create a new project. Then the variable should be set by OFS and the generator should work. Tracking stops automatically If a tacker does not find the selected feature in the next frame, the tracking process stops. If more than 120 frames have already been tracked, a window appears to select the minimum and maximum value in which the reason for the abort is displayed with e.g. Info: Tracker Woman Lost . If less than 120 frames have been processed, a message box should pop up with the message Tracking time insufficient . In this case, no output is generated because there is not enough data for the algorithm to work with. Tracking stops very often The selection of the tracking feature is tricky and requires some practice and experience. For a good tracking result, unique features in the video should be selected near the desired tacking position.","title":"OFS Integration"},{"location":"user-guide/ofs-integration/#open-funscripter-integration","text":"Currently we use a hacky lua script to communicate between the Python Funscript Generator and the Open Funscripter.","title":"Open Funscripter Integration"},{"location":"user-guide/ofs-integration/#installation-windows","text":"Download the latest packed Python Funscript Editor from github release page . Extract the Archiv. Download the latest funscript_generator.lua script from github release page . Move the downloaded funscript_generator.lua script to data/lua in your OFS directory. Open the funscript_generator.lua file and adjust the Settings.FunscriptGenerator and Settings.TmpFile variable. NOTE: You have to use use / or \\\\ for the \\ symbols in your path! Settings.FunscriptGenerator : Point to the extracted Python Funscript Editor program (better double check the complete path string to avoid errors later on). Settings.TmpFile : Specifies a temporary file location where to store the result (must be a file not a directory!). The file does not have to exist at the moment. The specified file will be generated from the Python Funscript Editor and will be overwritten automatically at the next time the generator is started! Now launch OFS. Navigate to View : Special functions : Custom Functions and select the funscript_generator.lua entry. Click the Button Bind Script (This may trigger the funscript generator, just ignore it for now). Navigate to Options : Keys : Dynamic and insert a shortcut for the funscript generator. Now you can use the shortcut at any position in the video to start the funscript generator.","title":"Installation (Windows)"},{"location":"user-guide/ofs-integration/#troubleshot","text":"If you have problems with the OFS integration setup first test if the app work in standalone mode by starting the funscript-editor.exe . This allows the source of the error to be narrowed down more quickly! If the standalone application works, look for your problem in the issues listed below. If the standalone application not work or your issue was not solved by a point listed below, open an issue with a detailed problem description and the full terminal window output if available.","title":"Troubleshot"},{"location":"user-guide/ofs-integration/#after-setting-the-min-and-max-value-after-tracking-no-points-are-inserted-in-ofs","text":"If the points are missing in OFS then most likely the variable Settings.TmpFile in the funscript_generator.lua script is set incorrectly or the generator crashes. A crash could happen if your PC does not have enough memory. The amount of memory required depends heavily on the video resolution!","title":"After setting the min and max value after tracking no points are inserted in OFS"},{"location":"user-guide/ofs-integration/#noting-happens-when-i-press-the-shortcut-for-the-funscript-generator","text":"In most cases, the variable Settings.FunscriptGenerator in the funscript_generator.lua script was not set correctly. If you are using an older version of the funscript_generator.lua you should download the latest version of the script from the github release page . With older funscript_generator.lua scripts there were e.g. problems with blanks in the path. Important: You have to use use / or \\\\ for the \\ symbols in your path!","title":"Noting happens when i press the Shortcut for the Funscript Generator"},{"location":"user-guide/ofs-integration/#when-calling-the-generator-only-a-message-box-is-displayed-with-the-message-video-file-was-not-specified","text":"In some cases OFS does not set the path to the video file within the lua script correctly (the variable VideoFilePath is empty). Mostly it helps to save the current project and/or create a new project. Then the variable should be set by OFS and the generator should work.","title":"When calling the generator, only a message box is displayed with the message: \"Video file was not specified!\""},{"location":"user-guide/ofs-integration/#tracking-stops-automatically","text":"If a tacker does not find the selected feature in the next frame, the tracking process stops. If more than 120 frames have already been tracked, a window appears to select the minimum and maximum value in which the reason for the abort is displayed with e.g. Info: Tracker Woman Lost . If less than 120 frames have been processed, a message box should pop up with the message Tracking time insufficient . In this case, no output is generated because there is not enough data for the algorithm to work with.","title":"Tracking stops automatically"},{"location":"user-guide/ofs-integration/#tracking-stops-very-often","text":"The selection of the tracking feature is tricky and requires some practice and experience. For a good tracking result, unique features in the video should be selected near the desired tacking position.","title":"Tracking stops very often"},{"location":"user-guide/ui/","text":"UI The build in UI use an embedded mpv video player and matplotlib to draw the actions timeseries at the bottom. UI Keyboard Shortcuts Key Function P Pause / Playback . Next frame , Previous frame [ Decrease speed ] Increase speed Ctrl + Shift + Left Previous Action Point Ctrl + Shift + Right Next Action Point Shift + L Loop Video W Move Stroke Indicator Up A Move Stroke Indicator Left S Move Stroke Indicator Down D Move Stroke Indicator Right Ctrl + I Invert Stroke Indicator Ctrl + Plus Increase Stroke Indicator Ctrl + Minus Decrease Stroke Indicator Gtrl + G Start Funscript Generator Shift + Pos1 First Action Point Shift + End Last Action Point Pos1 Jump to Video Start End Jump to Video End 0 Add Action Point at 0% 1 Add Action Point at 10% 2 Add Action Point at 20% 3 Add Action Point at 30% 4 Add Action Point at 40% 5 Add Action Point at 50% 6 Add Action Point at 60% 7 Add Action Point at 70% 8 Add Action Point at 80% 9 Add Action Point at 90%","title":"UI"},{"location":"user-guide/ui/#ui","text":"The build in UI use an embedded mpv video player and matplotlib to draw the actions timeseries at the bottom.","title":"UI"},{"location":"user-guide/ui/#ui-keyboard-shortcuts","text":"Key Function P Pause / Playback . Next frame , Previous frame [ Decrease speed ] Increase speed Ctrl + Shift + Left Previous Action Point Ctrl + Shift + Right Next Action Point Shift + L Loop Video W Move Stroke Indicator Up A Move Stroke Indicator Left S Move Stroke Indicator Down D Move Stroke Indicator Right Ctrl + I Invert Stroke Indicator Ctrl + Plus Increase Stroke Indicator Ctrl + Minus Decrease Stroke Indicator Gtrl + G Start Funscript Generator Shift + Pos1 First Action Point Shift + End Last Action Point Pos1 Jump to Video Start End Jump to Video End 0 Add Action Point at 0% 1 Add Action Point at 10% 2 Add Action Point at 20% 3 Add Action Point at 30% 4 Add Action Point at 40% 5 Add Action Point at 50% 6 Add Action Point at 60% 7 Add Action Point at 70% 8 Add Action Point at 80% 9 Add Action Point at 90%","title":"UI Keyboard Shortcuts"}]}